C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:88: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:107: LightningDeprecationWarning: DataModule property `val_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
Files already downloaded and verified
Files already downloaded and verified
Training and Evaluating: fitness Gen: 29 Run: 0
Files already downloaded and verified
C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:126: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
Files already downloaded and verified
Sanity Checking: 0it [00:00, ?it/s]
  | Name       | Type        | Params
-------------------------------------------
0 | BatchNorm1 | BatchNorm2d | 64
1 | BatchNorm2 | BatchNorm2d | 256
2 | BatchNorm3 | BatchNorm2d | 512
3 | pool       | MaxPool2d   | 0
4 | fc1        | Linear      | 4.2 M
5 | fc2        | Linear      | 524 K
6 | fc3        | Linear      | 5.1 K
7 | dropout1   | Dropout2d   | 0
8 | dropout2   | Dropout2d   | 0
-------------------------------------------
4.7 M     Trainable params
0         Non-trainable params
4.7 M     Total params
18.904    Total estimated model params size (MB)
Traceback (most recent call last):
  File "C:\Users\Jordan\Learning\UVM\Research\novel-feature-detector\train_and_eval.py", line 104, in <module>
    run()
  File "C:\Users\Jordan\Learning\UVM\Research\novel-feature-detector\train_and_eval.py", line 96, in run
    record_progress = helper.train_network(data_module=data_module, filters=filters_list[i], epochs=epochs, save_path=save_path, fixed_conv=fixed_conv, novelty_interval=int(args.novelty_interval), val_interval=int(args.test_accuracy_interval))
  File "C:\Users\Jordan\Learning\UVM\Research\novel-feature-detector\helper_hpc.py", line 44, in train_network
    trainer.fit(net, data_module)
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 771, in fit
    self._call_and_handle_interrupt(
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 724, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 812, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1237, in _run
    results = self._run_stage()
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1324, in _run_stage
    return self._run_train()
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1346, in _run_train
    self._run_sanity_check()
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1407, in _run_sanity_check
    val_loop._reload_evaluation_dataloaders()
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\loops\dataloader\evaluation_loop.py", line 239, in _reload_evaluation_dataloaders
    self.trainer.reset_val_dataloader()
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1959, in reset_val_dataloader
    self.num_val_batches, self.val_dataloaders = self._data_connector._reset_eval_dataloader(
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py", line 372, in _reset_eval_dataloader
    dataloaders = self._request_dataloader(mode, model=model)
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py", line 451, in _request_dataloader
    dataloader = source.dataloader()
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py", line 527, in dataloader
    return method()
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pl_bolts\datamodules\vision_datamodule.py", line 125, in val_dataloader
    return self._data_loader(self.dataset_val)
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pl_bolts\datamodules\vision_datamodule.py", line 132, in _data_loader
    return DataLoader(
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\torch\utils\data\dataloader.py", line 283, in __init__
    batch_sampler = BatchSampler(sampler, batch_size, drop_last)
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\torch\utils\data\sampler.py", line 215, in __init__
    raise ValueError("batch_size should be a positive integer value, "
ValueError: batch_size should be a positive integer value, but got batch_size=64