updating config
config: {'batch_size': 64, 'experiment_name': 'attempting to rewrite compute diversity fuction', 'evo_gens': 10, 'evo_pop': 10, 'evo_dataset_for_novelty': 'cifar10', 'evo_num_runs': 1, 'evo_tourney_size': 4, 'evo_num_winners': 2, 'evo_num_children': 10}
Files already downloaded and verified
Files already downloaded and verified
C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:88: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:107: LightningDeprecationWarning: DataModule property `val_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
Running Evolution for fitness
C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:126: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
  0%|                                                                                            | 0/1 [00:00<?, ?it/s]
Initializing
1649771468.8952038
  0%|                                                                                           | 0/10 [00:00<?, ?it/s]
torch.Size([64, 32, 32, 32])
tensor([[[-1.3939e-01,  6.1349e-03, -3.1028e-02,  ...,  6.1721e-02,
          -4.5007e-02, -1.0030e-01],
         [ 6.1349e-03, -8.4522e-03, -2.4113e-04,  ...,  1.3201e-03,
          -3.8951e-03,  1.1913e-02],
         [-3.1028e-02, -2.4113e-04, -1.6286e-02,  ...,  1.6556e-02,
          -1.3708e-02, -2.3873e-02],
         ...,
         [ 6.1721e-02,  1.3201e-03,  1.6556e-02,  ..., -3.3250e-02,
           2.3501e-02,  4.1813e-02],
         [-4.5007e-02, -3.8951e-03, -1.3708e-02,  ...,  2.3501e-02,
          -2.4507e-02, -2.5700e-02],
         [-1.0030e-01,  1.1913e-02, -2.3873e-02,  ...,  4.1813e-02,
          -2.5700e-02, -8.4692e-02]],
        [[-2.5866e-01,  2.0504e-02, -5.5662e-02,  ...,  1.0974e-01,
          -5.1177e-02, -2.0067e-01],
         [ 2.0504e-02, -3.6857e-03,  5.2550e-03,  ..., -7.4339e-03,
           3.0082e-03,  1.7516e-02],
         [-5.5662e-02,  5.2550e-03, -1.5516e-02,  ...,  2.3144e-02,
          -1.1001e-02, -4.4237e-02],
         ...,
         [ 1.0974e-01, -7.4339e-03,  2.3144e-02,  ..., -4.8061e-02,
           2.1688e-02,  8.4940e-02],
         [-5.1177e-02,  3.0082e-03, -1.1001e-02,  ...,  2.1688e-02,
          -1.3070e-02, -3.6908e-02],
         [-2.0067e-01,  1.7516e-02, -4.4237e-02,  ...,  8.4940e-02,
          -3.6908e-02, -1.5949e-01]],
        [[-3.1271e-01,  3.4350e-02, -6.4515e-02,  ...,  1.4349e-01,
          -4.8720e-02, -2.7962e-01],
         [ 3.4350e-02, -8.8613e-03,  7.0691e-03,  ..., -1.3493e-02,
           1.4530e-03,  3.6323e-02],
         [-6.4515e-02,  7.0691e-03, -2.1874e-02,  ...,  2.9962e-02,
          -1.1430e-02, -5.9572e-02],
         ...,
         [ 1.4349e-01, -1.3493e-02,  2.9962e-02,  ..., -6.9505e-02,
           2.2326e-02,  1.2745e-01],
         [-4.8720e-02,  1.4530e-03, -1.1430e-02,  ...,  2.2326e-02,
          -1.5633e-02, -3.6459e-02],
         [-2.7962e-01,  3.6323e-02, -5.9572e-02,  ...,  1.2745e-01,
          -3.6459e-02, -2.6160e-01]],
        ...,
        [[-1.4849e-01,  5.3613e-03, -3.4090e-02,  ...,  7.3010e-02,
          -5.2638e-02, -1.1398e-01],
         [ 5.3613e-03, -3.6498e-03,  9.6600e-04,  ..., -1.3141e-03,
           5.7176e-04,  7.3941e-03],
         [-3.4090e-02,  9.6600e-04, -1.2593e-02,  ...,  1.7799e-02,
          -1.1699e-02, -2.6687e-02],
         ...,
         [ 7.3010e-02, -1.3141e-03,  1.7799e-02,  ..., -3.8112e-02,
           2.5880e-02,  5.5383e-02],
         [-5.2638e-02,  5.7176e-04, -1.1699e-02,  ...,  2.5880e-02,
          -2.4371e-02, -3.7903e-02],
         [-1.1398e-01,  7.3941e-03, -2.6687e-02,  ...,  5.5383e-02,
          -3.7903e-02, -9.3245e-02]],
        [[-3.2018e-01,  4.0620e-02, -6.6452e-02,  ...,  1.4372e-01,
          -4.7951e-02, -2.8606e-01],
         [ 4.0620e-02, -1.7088e-02,  8.6772e-03,  ..., -1.2230e-02,
           6.3364e-04,  4.4615e-02],
         [-6.6452e-02,  8.6772e-03, -2.8629e-02,  ...,  3.3213e-02,
          -9.3814e-03, -6.2532e-02],
         ...,
         [ 1.4372e-01, -1.2230e-02,  3.3213e-02,  ..., -7.0734e-02,
           2.2252e-02,  1.2648e-01],
         [-4.7951e-02,  6.3364e-04, -9.3814e-03,  ...,  2.2252e-02,
          -1.5517e-02, -3.5133e-02],
         [-2.8606e-01,  4.4615e-02, -6.2532e-02,  ...,  1.2648e-01,
          -3.5133e-02, -2.6801e-01]],
        [[-3.7652e-01,  2.0603e-02, -9.7135e-02,  ...,  1.9655e-01,
          -3.6099e-02, -3.3328e-01],
         [ 2.0603e-02, -2.9173e-03,  7.0244e-03,  ..., -1.0275e-02,
           8.7991e-04,  1.8939e-02],
         [-9.7135e-02,  7.0244e-03, -3.0952e-02,  ...,  5.0067e-02,
          -7.3679e-03, -8.8306e-02],
         ...,
         [ 1.9655e-01, -1.0275e-02,  5.0067e-02,  ..., -1.0448e-01,
           1.7730e-02,  1.7555e-01],
         [-3.6099e-02,  8.7991e-04, -7.3679e-03,  ...,  1.7730e-02,
          -8.9343e-03, -2.7998e-02],
         [-3.3328e-01,  1.8939e-02, -8.8306e-02,  ...,  1.7555e-01,
          -2.7998e-02, -3.0015e-01]]], grad_fn=<DivBackward0>)
{'0': 332.57885113172233}
torch.Size([64, 64, 32, 32])
tensor([[[-2.0836e-01, -3.1142e-02, -3.0281e-02,  ..., -4.1813e-02,
           1.1079e-01, -1.4615e-01],
         [-3.1142e-02, -7.3886e-02, -3.5365e-02,  ..., -2.0962e-02,
           3.6531e-02, -2.9015e-02],
         [-3.0281e-02, -3.5365e-02, -4.7331e-02,  ...,  1.8383e-03,
           3.4531e-02, -2.6914e-02],
         ...,
         [-4.1813e-02, -2.0962e-02,  1.8383e-03,  ..., -1.1967e-01,
           3.2177e-02, -4.1837e-02],
         [ 1.1079e-01,  3.6531e-02,  3.4531e-02,  ...,  3.2177e-02,
          -1.0711e-01,  1.1053e-01],
         [-1.4615e-01, -2.9015e-02, -2.6914e-02,  ..., -4.1837e-02,
           1.1053e-01, -1.9165e-01]],
        [[-3.3404e-02, -7.3571e-03,  7.2518e-03,  ..., -6.9268e-03,
           1.1284e-02, -2.2293e-02],
         [-7.3571e-03, -4.8142e-02, -1.4168e-02,  ..., -2.2685e-02,
           1.1633e-02, -7.9367e-03],
         [ 7.2518e-03, -1.4168e-02, -1.5238e-02,  ..., -7.3056e-03,
           6.8608e-03, -1.4730e-04],
         ...,
         [-6.9268e-03, -2.2685e-02, -7.3056e-03,  ..., -4.2064e-02,
           8.1478e-03, -2.0170e-02],
         [ 1.1284e-02,  1.1633e-02,  6.8608e-03,  ...,  8.1478e-03,
          -2.3334e-02,  2.1882e-02],
         [-2.2293e-02, -7.9367e-03, -1.4730e-04,  ..., -2.0170e-02,
           2.1882e-02, -5.1934e-02]],
        [[-8.0206e-02, -7.6761e-03,  5.8437e-03,  ..., -5.7099e-03,
           2.2648e-02, -5.7701e-02],
         [-7.6761e-03, -4.4131e-01, -2.6771e-01,  ..., -2.8868e-01,
           2.3724e-01, -1.3997e-01],
         [ 5.8437e-03, -2.6771e-01, -2.2836e-01,  ..., -1.9806e-01,
           1.8686e-01, -9.9602e-02],
         ...,
         [-5.7099e-03, -2.8868e-01, -1.9806e-01,  ..., -2.9795e-01,
           1.9259e-01, -1.2616e-01],
         [ 2.2648e-02,  2.3724e-01,  1.8686e-01,  ...,  1.9259e-01,
          -2.0093e-01,  1.2722e-01],
         [-5.7701e-02, -1.3997e-01, -9.9602e-02,  ..., -1.2616e-01,
           1.2722e-01, -1.5900e-01]],
        ...,
        [[-1.7056e-01, -2.3229e-02, -4.0887e-02,  ...,  2.3966e-02,
           1.0782e-01, -1.5706e-01],
         [-2.3229e-02, -2.7307e-02, -2.4606e-02,  ...,  3.2774e-03,
           1.3283e-02, -1.6419e-02],
         [-4.0887e-02, -2.4606e-02, -5.3981e-02,  ...,  1.3506e-02,
           4.1056e-02, -5.0347e-02],
         ...,
         [ 2.3966e-02,  3.2774e-03,  1.3506e-02,  ..., -5.8890e-02,
          -2.2400e-02,  2.1586e-02],
         [ 1.0782e-01,  1.3283e-02,  4.1056e-02,  ..., -2.2400e-02,
          -9.9298e-02,  1.2164e-01],
         [-1.5706e-01, -1.6419e-02, -5.0347e-02,  ...,  2.1586e-02,
           1.2164e-01, -2.0137e-01]],
        [[-1.1313e-01,  3.0731e-02,  4.1239e-02,  ...,  2.0449e-02,
          -1.6859e-02, -6.0618e-02],
         [ 3.0731e-02, -3.8067e-01, -2.5378e-01,  ..., -2.8294e-01,
           2.3884e-01, -1.0892e-01],
         [ 4.1239e-02, -2.5378e-01, -2.2997e-01,  ..., -1.9563e-01,
           2.0605e-01, -8.1216e-02],
         ...,
         [ 2.0449e-02, -2.8294e-01, -1.9563e-01,  ..., -3.1426e-01,
           2.0355e-01, -1.3984e-01],
         [-1.6859e-02,  2.3884e-01,  2.0605e-01,  ...,  2.0355e-01,
          -2.4301e-01,  1.3705e-01],
         [-6.0618e-02, -1.0892e-01, -8.1216e-02,  ..., -1.3984e-01,
           1.3705e-01, -2.2508e-01]],
        [[-3.9321e-02, -1.0975e-02,  1.0762e-02,  ..., -4.4353e-03,
           7.7016e-03, -3.0972e-02],
         [-1.0975e-02, -3.7036e-01, -1.9463e-01,  ..., -2.7203e-01,
           2.2320e-01, -8.5506e-02],
         [ 1.0762e-02, -1.9463e-01, -1.4036e-01,  ..., -1.4774e-01,
           1.4508e-01, -4.3888e-02],
         ...,
         [-4.4353e-03, -2.7203e-01, -1.4774e-01,  ..., -2.4730e-01,
           1.7324e-01, -8.5596e-02],
         [ 7.7016e-03,  2.2320e-01,  1.4508e-01,  ...,  1.7324e-01,
          -1.9241e-01,  8.9985e-02],
         [-3.0972e-02, -8.5506e-02, -4.3888e-02,  ..., -8.5596e-02,
           8.9985e-02, -1.1497e-01]]], grad_fn=<DivBackward0>)
  0%|                                                                                            | 0/1 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\Jordan\Learning\UVM\Research\novel-feature-detector\evolution.py", line 220, in <module>
    run()
  File "C:\Users\Jordan\Learning\UVM\Research\novel-feature-detector\evolution.py", line 186, in run
    solution_over_time, fitness_over_time = evolution(generations=n_iters, population_size=pop_size, num_children=num_children, tournament_size=tournament_size, num_winners=num_winners, evolution_type=run_name)
  File "C:\Users\Jordan\Learning\UVM\Research\novel-feature-detector\evolution.py", line 87, in evolution
    model.fitness =  net.get_fitness(net_input)
  File "C:\Users\Jordan\Learning\UVM\Research\novel-feature-detector\net.py", line 158, in get_fitness
    novelty_score = self.compute_feature_novelty()
  File "C:\Users\Jordan\Learning\UVM\Research\novel-feature-detector\net.py", line 257, in compute_feature_novelty
    div = np.abs(self.activations[layer][0][batch][channel].detach().cpu().numpy() - self.activations[layer][0][batch][channel2].detach().cpu().numpy()).sum()
  File "C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\numpy\core\_methods.py", line 48, in _sum
    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
KeyboardInterrupt