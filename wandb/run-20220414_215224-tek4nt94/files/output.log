C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:88: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:107: LightningDeprecationWarning: DataModule property `val_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
Files already downloaded and verified
Files already downloaded and verified
Training and Evaluating: random Gen: 9 Run: 0
cuda:0
Files already downloaded and verified
Files already downloaded and verified
C:\Users\Jordan\anaconda3\envs\EC2\lib\site-packages\pytorch_lightning\core\datamodule.py:126: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.
  rank_zero_deprecation(
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name        | Type        | Params
--------------------------------------------
0 | BatchNorm1  | BatchNorm2d | 64
1 | BatchNorm2  | BatchNorm2d | 256
2 | BatchNorm3  | BatchNorm2d | 512
3 | pool        | MaxPool2d   | 0
4 | fc1         | Linear      | 4.2 M
5 | fc2         | Linear      | 524 K
6 | fc3         | Linear      | 5.1 K
7 | dropout1    | Dropout2d   | 0
8 | dropout2    | Dropout2d   | 0
9 | conv_layers | ModuleList  | 1.1 M
--------------------------------------------
5.9 M     Trainable params
0         Non-trainable params
5.9 M     Total params
23.409    Total estimated model params size (MB)





























Epoch 3:  80%|█████████████████████████████████████▌         | 625/782 [01:34<00:23,  6.58it/s, loss=0.966, v_num=nt94]

















































Epoch 7:  80%|█████████████████████████████████████▌         | 625/782 [04:18<01:04,  2.42it/s, loss=0.741, v_num=nt94]



















































Epoch 11:  80%|████████████████████████████████████▊         | 625/782 [07:03<01:46,  1.48it/s, loss=0.664, v_num=nt94]


















































Epoch 15:  80%|████████████████████████████████████▊         | 625/782 [09:47<02:27,  1.06it/s, loss=0.597, v_num=nt94]















































Epoch 19:  80%|████████████████████████████████████▊         | 625/782 [12:24<03:06,  1.19s/it, loss=0.553, v_num=nt94]















































Epoch 23:  80%|████████████████████████████████████▊         | 625/782 [15:00<03:46,  1.44s/it, loss=0.527, v_num=nt94]














































Epoch 27:  80%|████████████████████████████████████▊         | 625/782 [17:36<04:25,  1.69s/it, loss=0.535, v_num=nt94]





















































Epoch 31:  80%|████████████████████████████████▊        | 625/782 [10:36:35<2:39:54, 61.11s/it, loss=0.497, v_num=nt94]





















































Epoch 35:  80%|████████████████████████████████▊        | 625/782 [10:39:34<2:40:39, 61.40s/it, loss=0.493, v_num=nt94]




















































Epoch 39:  80%|████████████████████████████████▊        | 625/782 [10:42:25<2:41:22, 61.67s/it, loss=0.464, v_num=nt94]

















































Epoch 43:  80%|████████████████████████████████▊        | 625/782 [10:45:10<2:42:04, 61.94s/it, loss=0.484, v_num=nt94]


















































Epoch 47:  80%|████████████████████████████████▊        | 625/782 [10:47:51<2:42:44, 62.19s/it, loss=0.475, v_num=nt94]
















































Epoch 51:  80%|████████████████████████████████▊        | 625/782 [10:50:30<2:43:24, 62.45s/it, loss=0.511, v_num=nt94]













































Epoch 55:  80%|████████████████████████████████▊        | 625/782 [10:53:08<2:44:04, 62.70s/it, loss=0.468, v_num=nt94]














































Epoch 59:  80%|████████████████████████████████▊        | 625/782 [10:55:48<2:44:44, 62.96s/it, loss=0.478, v_num=nt94]














































Epoch 63:  80%|████████████████████████████████▊        | 625/782 [10:58:23<2:45:23, 63.21s/it, loss=0.499, v_num=nt94]














































Epoch 67:  80%|████████████████████████████████▊        | 625/782 [11:01:01<2:46:02, 63.46s/it, loss=0.449, v_num=nt94]














































Epoch 71:  80%|████████████████████████████████▊        | 625/782 [11:03:36<2:46:41, 63.71s/it, loss=0.462, v_num=nt94]











































Epoch 75:  80%|████████████████████████████████▊        | 625/782 [11:06:09<2:47:20, 63.95s/it, loss=0.489, v_num=nt94]












































Epoch 79:  80%|████████████████████████████████▊        | 625/782 [11:08:42<2:47:58, 64.20s/it, loss=0.516, v_num=nt94]













































Epoch 83:  80%|████████████████████████████████▊        | 625/782 [11:11:17<2:48:37, 64.44s/it, loss=0.467, v_num=nt94]













































Epoch 87:  80%|████████████████████████████████▊        | 625/782 [11:13:50<2:49:16, 64.69s/it, loss=0.466, v_num=nt94]









































Epoch 91:  80%|████████████████████████████████▊        | 625/782 [11:16:13<2:49:52, 64.92s/it, loss=0.443, v_num=nt94]













































Epoch 95:  80%|████████████████████████████████▊        | 625/782 [11:18:48<2:50:30, 65.17s/it, loss=0.457, v_num=nt94]




















