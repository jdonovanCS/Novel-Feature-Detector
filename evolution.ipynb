{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d19e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import scikits.bootstrap as bootstrap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Danger, Will Robinson! (not a scalable hack, and may surpress other helpful warning other than for ill-conditioned bootstrapped CI distributions)\n",
    "import testcopy as test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eca76d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 3])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "(50, 4, 32, 30, 30)\n",
      "(50, 4, 64, 28, 28)\n",
      "(50, 4, 128, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "# test.run()\n",
    "random_image_paths = test.create_random_images()\n",
    "trainloader = test.load_random_images(random_image_paths)\n",
    "activations = test.get_activations(trainloader)\n",
    "for k, v in activations.items():\n",
    "    print(np.array(v).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f0a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "            ),\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2ca412517b8>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2ca4b286908>,\n",
       " ('plane',\n",
       "  'car',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'deer',\n",
       "  'dog',\n",
       "  'frog',\n",
       "  'horse',\n",
       "  'ship',\n",
       "  'truck'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evolution(generations, population_size, num_children, tournament_size, num_winners=1, evolution_type=\"regularized\"):\n",
    "    \"\"\"Algorithm for regularized evolution (i.e. aging evolution).\n",
    "\n",
    "    Follows \"Algorithm 1\" in Real et al. \"Regularized Evolution for Image\n",
    "    Classifier Architecture Search\".\n",
    "\n",
    "    Args:\n",
    "      generations: the number of generations the algorithm should run for.\n",
    "      population_size: the number of individuals to keep in the population.\n",
    "      tournament_size: the number of individuals that should participate in each\n",
    "          tournament.\n",
    "\n",
    "    Returns:\n",
    "      history: a list of `Model` instances, representing all the models computed\n",
    "          during the evolution experiment.\n",
    "    \"\"\"\n",
    "    population = collections.deque()\n",
    "    history = []  # Not used by the algorithm, only used to report results.\n",
    "    solutions_over_time = []\n",
    "    fitness_over_time = []\n",
    "    novelty_over_time = []\n",
    "\n",
    "    # Initialize the population with random models.\n",
    "    while len(population) < population_size:\n",
    "        activations = test.get_activations(trainloader).values()[2]\n",
    "        model.accuracy = train_and_eval(model.arch)\n",
    "        population.append(model)\n",
    "        history.append(model)\n",
    "    \n",
    "    for ind in population:\n",
    "        ind.novelty = compute_novelty(ind.arch, history)\n",
    "        \n",
    "    # Carry out evolution in cycles. Each cycle produces a model and removes\n",
    "    # another.\n",
    "    for i in range(generations):\n",
    "#     while len(history) < generations:\n",
    "        \n",
    "        parents = []\n",
    "#         if evolution_type == \"regularized\":\n",
    "#             while len(sample) < sample_size:\n",
    "#             # Inefficient, but written this way for clarity. In the case of neural\n",
    "#             # nets, the efficiency of this line is irrelevant because training neural\n",
    "#             # nets is the rate-determining step.\n",
    "#                 candidate = random.choice(list(population))\n",
    "#                 sample.append(candidate)\n",
    "\n",
    "#             # The parent is the best model in the sample.\n",
    "#             parent = max(sample, key=lambda i: i.accuracy)\n",
    "#             parents.append(parent)\n",
    "#         else:    \n",
    "        while len(parents) < num_children and evolution_type != \"random\":\n",
    "        # Sample randomly chosen models from the current population.\n",
    "            tournament = []\n",
    "            while len(tournament) < tournament_size:\n",
    "            # Inefficient, but written this way for clarity. In the case of neural\n",
    "            # nets, the efficiency of this line is irrelevant because training neural\n",
    "            # nets is the rate-determining step.\n",
    "                candidate = random.choice(list(population))\n",
    "                tournament.append(candidate)\n",
    "\n",
    "            # The parent is the best model in the sample.\n",
    "            if evolution_type == \"novelty\":\n",
    "                parents.extend(sorted(tournament, key=lambda i: i.novelty, reverse=True)[:num_winners])\n",
    "            elif evolution_type == \"mixed\":\n",
    "                novelties = collections.deque(sorted(tournament, key=lambda i: i.novelty, reverse=True))\n",
    "                fitnesses = collections.deque(sorted(tournament, key=lambda i: i.accuracy, reverse=True))\n",
    "                for i in range(num_winners):\n",
    "                    if random.uniform(0, 1) <= .5:\n",
    "                        parents.append(novelties.popleft())\n",
    "                    else:\n",
    "                        parents.append(fitnesses.popleft())\n",
    "            else:\n",
    "                parents.extend(sorted(tournament, key=lambda i: i.accuracy, reverse=True)[:num_winners])\n",
    "        \n",
    "\n",
    "        # Create the child model and store it.\n",
    "        for parent in parents:\n",
    "            child = Model()\n",
    "            child.arch = mutate_arch(parent.arch)\n",
    "            child.accuracy = train_and_eval(child.arch)\n",
    "            population.append(child)\n",
    "            history.append(child)\n",
    "            if len(history) > population_size + num_children:\n",
    "                history=history[1:]\n",
    "            population[-1].novelty = compute_novelty(child.arch, history)\n",
    "\n",
    "\n",
    "            # Remove the oldest model.\n",
    "        if evolution_type == 'regularized':\n",
    "            population = list(population)[:population_size]\n",
    "            \n",
    "        if evolution_type == 'fitness':\n",
    "            population = sorted(population, key=lambda i: i.accuracy, reverse=True)[:population_size]\n",
    "                \n",
    "        if evolution_type == 'novelty':\n",
    "            population = sorted(population, key=lambda i: i.novelty, reverse=True)[:population_size]\n",
    "            \n",
    "        if evolution_type == 'mixed':\n",
    "            population = sorted(population, key=lambda i: i.accuracy, reverse=True)\n",
    "            new_population = population[:int(.5*population_size)]\n",
    "            population = new_population + sorted(population, key=lambda i: i.novelty, reverse=True)[:int(population_size*.5)]\n",
    "            population = sorted(population, key=lambda i: i.accuracy, reverse=True)[:population_size]\n",
    "        \n",
    "        if evolution_type == 'random':\n",
    "            population = [sorted(population, key=lambda i: i.accuracy, reverse=True)[0]]\n",
    "            history = []\n",
    "            while len(population) < population_size:\n",
    "                model = Model()\n",
    "                model.arch = random_architecture()\n",
    "                model.accuracy = train_and_eval(model.arch)\n",
    "                population.append(model)\n",
    "                history.append(model)\n",
    "    \n",
    "            for ind in population:\n",
    "                ind.novelty = compute_novelty(ind.arch, history)\n",
    "        \n",
    "#         print([x.accuracy for x in sorted(population, key=lambda i: i.accuracy, reverse=True)])\n",
    "        fitness_over_time.append(1+(sorted(population, key=lambda i: i.accuracy, reverse=True)[0].accuracy))\n",
    "        solutions_over_time.append((sorted(population, key=lambda i: i.accuracy, reverse=True)[0].arch))\n",
    "        novelty_over_time.append(np.mean([x.novelty for x in population]))\n",
    "\n",
    "    return history, solutions_over_time, np.array(fitness_over_time), novelty_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f102501f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'load_CIFAR_10'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28068/688013721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_CIFAR_10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'load_CIFAR_10'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e35a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
