#!/bin/bash
## Required PBS Directives --------------------------------------
#PBS -A ERDCV0089CDAG
#PBS -q standard
#PBS -l select=1:ncpus=22:mpiprocs=2:ngpus=1
#PBS -l walltime=8:00:00
#PBS -l application=novel-feature-detector
#PBS -j oe

# env | sort
# hostname
# uname -a
# lsb_release -a

## Execution Block ----------------------------------------------
# Environment Setup
# cd to your scratch directory in /work
cd $WORK/rditljtd/Novel-Feature-Detector

# create a job-specific subdirectory based on JOBID and cd to it
# JOBID=`echo ${PBS_JOBID} | cut -d '.' -f 1`
# if [ ! -d ${JOBID} ]; then
#   mkdir -p ${JOBID}
# fi
# cd ${JOBID}

## Launching -----------------------------------------------------

# copy executable from $HOME and submit it
#cp ${HOME}/oil/main.py .
#cp ${HOME}/oil/stats.py .
#cp ${HOME}/oil/neural_arch.py .

#cp ${HOME}/OilPanReplacement/mainStudy1_AllChoice.py .
#cp ${HOME}/OilPanReplacement/stats.py .

module load $PROJECTS_HOME/datools/modulefiles/anaconda/3
source $HOME/.bashrc
conda activate EC2

#ccmrun python ${HOME}/amrdec_oil/main.py ${JOBID} > out.dat

ccmrun python train_and_eval.py --batch_size=64 --evo_tourney_size=4 --evo_num_winners=2 --evo_dataset_for_novelty=cifar10 --evo_pop_size=20 --evo_num_children=20 --evo_num_runs=5 --evo_gens=50 --experiment_name="hpc full cifar10 val diversity" --dataset=cifar10 --training_interval=0.2 --epochs=96 --novelty_interval=1 --test_accuracy_interval=4 --random --skip=2